# Classical Machine Learning
Classical_Machine_learning_Repository[https://github.com/anubhavsharma430/Classical-Machine-Learning] <br>
The Repository contains all the model of which is use in the Classical Machine Learning. The Repo Contain file both version of notebook file and python script file and each file contains code in both scratch code form and Libraries use form. These file contains all code in moduler basis having a vision of the use of the functions in other projects and also for better understanding of the code.<br>
<br>
<br>
## The Notebook File
The notebook file can be use to understanding the basis model of the algorithm by using scratch file and the scripting file
<br>
## The Script File
The Script file is the direct use file which can be directly run over your device. The Script file having scratch code is fully modular and can be use a user base library for the model training or for any project. The library form coded file can also use a user base library but it do some function on its own.
<br>
<br>
<br>
### Classification Algorithms
Classification is one of the most important aspects of supervised learning. In this article, we will discuss the various classification algorithms like logistic regression, naive bayes, decision trees, random forests and many more. We will go through each of the algorithm’s classification properties and how they work.
<br>
#### Decision Tree
Decision Tree algorithms are used for both predictions as well as classification in machine learning. Using the decision tree with a given set of inputs, one can map the various outcomes that are a result of the consequences or decisions.
<br>
#### Logistic Regression
logistic_Regression[https://github.com/anubhavsharma430/Classical-Machine-Learning/tree/master/Classification/Logistic%20Regression]<br>
We use logistic regression for the binary classification of data-points. We perform categorical classification such that an output belongs to either of the two classes (1 or 0). For example – we can predict whether it will rain today or not, based on the current weather conditions.<br>
Two of the important parts of logistic regression are Hypothesis and Sigmoid Curve. With the help of this hypothesis, we can derive the likelihood of the event. The data generated from this hypothesis can fit into the log function that creates an S-shaped curve known as “sigmoid”. Using this log function, we can further predict the category of class.
<br>
##### Bi-Class Classification
Bi_class_classifier[https://github.com/anubhavsharma430/Classical-Machine-Learning/tree/master/Classification/Logistic%20Regression/Bi%20Class%20Classification]<br>
##### Multi-Class Classification
Multi_class_classifier[https://github.com/anubhavsharma430/Classical-Machine-Learning/tree/master/Classification/Logistic%20Regression/Multi%20Class%20Classification]<br>
<br>
#### K-Nearest Neighbour
K-nearest neighbors is one of the most basic yet important classification algorithms in machine learning. KNNs belong to the supervised learning domain and have several applications in pattern recognition, data mining, and intrusion detection.<br>
These KNNs are used in real-life scenarios where non-parametric algorithms are required. These algorithms do not make any assumptions about how the data is distributed. When we are given prior data, the KNN classifies the coordinates into groups that are identified by a specific attribute.
<br>
#### Naive Bayes
Naive Bayes is one of the powerful machine learning algorithms that is used for classification. It is an extension of the Bayes theorem wherein each feature assumes independence. It is used for a variety of tasks such as spam filtering and other areas of text classification.
<br>
#### Support Vector Machine
Support Vector Machines are a type of supervised machine learning algorithm that provides analysis of data for classification and regression analysis. While they can be used for regression, SVM is mostly used for classification. We carry out plotting in the n-dimensional space. The value of each feature is also the value of the specified coordinate. Then, we find the ideal hyperplane that differentiates between the two classes.<br>
These support vectors are the coordinate representations of individual observation. It is a frontier method for segregating the two classes.<br>
<br>
<br>
<br>
### Regression Algorithms
<br>
<br>
#### Linear Regression
<br>
#### Decision Tree Regression
<br>
#### Support Vector Regression
