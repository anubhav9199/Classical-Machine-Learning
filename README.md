# Classical Machine Learning
Classical_Machine_learning_Repository[https://github.com/anubhavsharma430/Classical-Machine-Learning] <br>
The Repository contains all the model of which is use in the Classical Machine Learning. The Repo Contain file both version of notebook file and python script file and each file contains code in both scratch code form and Libraries use form. These file contains all code in moduler basis having a vision of the use of the functions in other projects and also for better understanding of the code.<br>
<br>
<br>
## The Notebook File
The notebook file can be use to understanding the basis model of the algorithm by using scratch file and the scripting file
<br>
## The Script File
The Script file is the direct use file which can be directly run over your device. The Script file having scratch code is fully modular and can be use a user base library for the model training or for any project. The library form coded file can also use a user base library but it do some function on its own.
<br>
<br>
<br>
### Classification Algorithms
Classification is one of the most important aspects of supervised learning. In this article, we will discuss the various classification algorithms like logistic regression, naive bayes, decision trees, random forests and many more. We will go through each of the algorithm‚Äôs classification properties and how they work.
<br>
#### Decision Tree
Decision Tree algorithms are used for both predictions as well as classification in machine learning. Using the decision tree with a given set of inputs, one can map the various outcomes that are a result of the consequences or decisions.
<br>
#### Logistic Regression
logistic_Regression[https://github.com/anubhavsharma430/Classical-Machine-Learning/tree/master/Classification/Logistic%20Regression]<br>
We use logistic regression for the binary classification of data-points. We perform categorical classification such that an output belongs to either of the two classes (1 or 0). For example ‚Äì we can predict whether it will rain today or not, based on the current weather conditions.<br>
Two of the important parts of logistic regression are Hypothesis and Sigmoid Curve. With the help of this hypothesis, we can derive the likelihood of the event. The data generated from this hypothesis can fit into the log function that creates an S-shaped curve known as ‚Äúsigmoid‚Äù. Using this log function, we can further predict the category of class.
<br>
##### Bi-Class Classification
Bi_class_classifier[https://github.com/anubhavsharma430/Classical-Machine-Learning/tree/master/Classification/Logistic%20Regression/Bi%20Class%20Classification]<br>
Logistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable, although many more complex extensions exist. In regression analysis, logistic regression (or logit regression) is estimating the parameters of a logistic model (a form of binary regression). It is a Discriminate Learning Algorithm which means that it try to find posterior probability over classes directly without the envolvement of likelihood probabilities.<br>
In statistics, the logistic model is used to model the probability of a certain class or event existing such as pass/fail, win/lose, alive/dead, True/False or healthy/sick. <br>
This can be extended to Classify several classes of events such as determining whether an image contains a cat, dog, lion, etc.
This code contains only about how we can fit a logistic model over user given dataset and also to get a good output result out of it. The code written keeping vision of object oriented programing which means that the code is fully moduler so that to keep in mind about the use of the functions in other programs also.
<br>
##### Multi-Class Classification
Multi_class_classifier[https://github.com/anubhavsharma430/Classical-Machine-Learning/tree/master/Classification/Logistic%20Regression/Multi%20Class%20Classification]<br>
Logistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable, although many more complex extensions exist. In regression analysis, logistic regression (or logit regression) is estimating the parameters of a logistic model (a form of binary regression). It is a Discriminate Learning Algorithm which means that it try to find posterior probability over classes directly without the envolvement of likelihood probabilities.<br>
In statistics, the logistic model is used to model the probability of a certain class or event existing such as pass/fail, win/lose, alive/dead, True/False or healthy/sick.<br>
This can be extended to Classify several classes of events such as determining whether an image contains a cat, dog, lion, etc.<br>
This code contains only about how we can fit a logistic model over user given dataset and also to get a good output result out of it. The code written keeping vision of object oriented programing which means that the code is fully moduler so that to keep in mind about the use of the functions in other programs also. 
<br>
#### K-Nearest Neighbour
K-nearest neighbors is one of the most basic yet important classification algorithms in machine learning. KNNs belong to the supervised learning domain and have several applications in pattern recognition, data mining, and intrusion detection.<br>
These KNNs are used in real-life scenarios where non-parametric algorithms are required. These algorithms do not make any assumptions about how the data is distributed. When we are given prior data, the KNN classifies the coordinates into groups that are identified by a specific attribute.
<br>
#### Naive Bayes
Naive Bayes is one of the powerful machine learning algorithms that is used for classification. It is an extension of the Bayes theorem wherein each feature assumes independence. It is used for a variety of tasks such as spam filtering and other areas of text classification.
<br>
#### Support Vector Machine
Support Vector Machines are a type of supervised machine learning algorithm that provides analysis of data for classification and regression analysis. While they can be used for regression, SVM is mostly used for classification. We carry out plotting in the n-dimensional space. The value of each feature is also the value of the specified coordinate. Then, we find the ideal hyperplane that differentiates between the two classes.<br>
These support vectors are the coordinate representations of individual observation. It is a frontier method for segregating the two classes.<br>
<br>
<br>
<br>
### Regression Algorithms
<br>
<br>
#### Linear Regression
The methodology for measuring the relationship between the two continuous variables is known as Linear regression. It comprises of two variables ‚Äì
    Independent Variable ‚Äì ‚Äúx‚Äù
    Dependent Variable ‚Äì ‚Äúy‚Äù
In a simple linear regression, the predictor value is an independent value that does not have any underlying dependency on any variable. The relationship between x and y is described as follows ‚Äì
$$y = mx + c$$
Here, m is the slope and c is the intercept.
Based on this equation, we can calculate the output that will be through the relationship exhibited between the dependent and the independent variable.
top machine learning algorithm
<br>
#### Decision Tree Regression
A decision tree is a flowchart-like structure in which each internal node represents a test on a feature (e.g. whether a coin flip comes up heads or tails) , each leaf node represents a class label (decision taken after computing all features) and branches represent conjunctions of features that lead to those class labels. The paths from root to leaf represent classification rules.<br>
Decision trees are constructed via an algorithmic approach that identifies ways to split a data set based on different conditions. It is one of the most widely used and practical methods for supervised learning. Decision Trees are a non-parametric supervised learning method used for both classification and regression tasks.<br>
Tree models where the target variable can take a discrete set of values are called classification trees. Decision trees where the target variable can take continuous values (typically real numbers) are called regression trees. Classification And Regression Tree (CART) is general term for this.
<br>
#### Support Vector Regression
Support Vector Regression(SVR) is quite different than other Regression models. It uses the Support Vector Machine(SVM, a classification algorithm) algorithm to predict a continuous variable. While other linear regression models try to minimize the error between the predicted and the actual value, Support Vector Regression tries to fit the best line within a predefined or threshold error value. What SVR does in this sense, it tries to classify all the prediction lines in two types, ones that pass through the error boundary( space separated by two parallel lines) and ones that don‚Äôt. Those lines which do not pass the error boundary are not considered as the difference between the predicted value and the actual value has exceeded the error threshold, ùûÆ(epsilon). The lines that pass, are considered for a potential support vector to predict the value of an unknown. The following illustration will help you to grab this concept.
