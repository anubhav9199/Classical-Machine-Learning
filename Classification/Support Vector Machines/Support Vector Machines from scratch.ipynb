{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine from Scratch using SMO\n",
    "Support Vector Machines are a type of supervised machine learning algorithm that provides analysis of data for classification and regression analysis. While they can be used for regression, SVM is mostly used for classification. We carry out plotting in the n-dimensional space. The value of each feature is also the value of the specified coordinate. Then, we find the ideal hyperplane that differentiates between the two classes.<br>\n",
    "These support vectors are the coordinate representations of individual observation. It is a frontier method for segregating the two classes.<br>\n",
    "This machine learning model is able to generalise between two different classes if the set of labelled data is provided in the training set to the algorithm. The main function of the SVM is to check for that hyperplane that is able to distinguish between the two classes.<br>\n",
    "I use Sequential Minimal Optimization Algorithm for the fast result over SVM Model. John Platt from Microsoft gave this amazing technique to train the model in a fast way. In this SMO actually check some of the lambdas of data which is find by the SVM over KKT Conditions. If any of the lambdas fit all the conditions then it will be treated as Support Vector for the training and fixing the Hyperplane.\n",
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theta Function\n",
    "Funtion to return thetas after the SVM trains itself on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thetas():\n",
    "    a=lambdas*C_train.T\n",
    "    theta=np.matmul(x.T,a.T)\n",
    "    neg_x=x[np.where(C_train==-1)[0]]\n",
    "    pos_x=x[np.where(C_train==1)[0]]\n",
    "    pos=np.min(1-np.matmul(theta.T,pos_x.T))\n",
    "    neg=np.max(-1-np.matmul(theta.T,neg_x.T))\n",
    "    theta0=(pos+neg)/2\n",
    "    return theta,theta0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Function\n",
    "Funtion to calculate Error between new lambdas and old lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E(i,b):\n",
    "    fx=np.sum((C_train*lambdas)*np.matmul(x,x[i].T))+b\n",
    "    return fx-C_train[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L and H Bound Function\n",
    "Funtion to find upper and lower bounds which don't voilate KKT condition. L is lower bound and H is upper bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LnH(i,j,regularize):\n",
    "    if C_train[i]!=C_train[j]:\n",
    "        L=max(0, lambdas[j]-lambdas[i])\n",
    "        H=min(regularize,regularize+lambdas[j]-lambdas[i])\n",
    "    if C_train[i]==C_train[j]:\n",
    "        L=max(0,lambdas[i]+lambdas[j]-regularize)\n",
    "        H=min(regularize,lambdas[i]+lambdas[j])\n",
    "    return L,H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Eta Function\n",
    "Funtion to return inner product (or implement some kernel funtion K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_eta(i,j):\n",
    "    return (2*np.matmul(x[i],x[j].T)-np.matmul(x[i],x[i].T)-np.matmul(x[j],x[j].T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute B-Threshold Function\n",
    "Funtion to compute threshold i.e. B which is compute after finding the lambdas so that it can satisfied the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_b(i,j,b,E1,E2,R):\n",
    "    \n",
    "    # Finding y*(alphai - aplhai_old) & y(alphaj - alphaj_old)\n",
    "    I=C_train[i]*(lambdas[i]-lambdas_old[i])\n",
    "    J=C_train[j]*(lambdas[j]-lambdas_old[j])\n",
    "    \n",
    "    # Finding b1 and b2\n",
    "    b1=b-E1-(I*np.matmul(x[i],x[i].T))-(J*np.matmul(x[i],x[j].T))\n",
    "    b2=b-E2-(I*np.matmul(x[i],x[j].T))-(J*np.matmul(x[j],x[j].T))\n",
    "    \n",
    "    if lambdas[i]>0 and lambdas[i]<R:\n",
    "        b=b1\n",
    "    \n",
    "    elif lambdas[j]>0 and lambdas[j]<R:\n",
    "        b=b2\n",
    "    \n",
    "    else:\n",
    "        b=(b1+b2)/2\n",
    "    \n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cliping Function\n",
    "Function to clip the value of 'Lagrange Multiplier' if they voilate KKT condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(H,L,j):\n",
    "    \n",
    "    if lambdas[j]>H:\n",
    "        lambdas[j]=H\n",
    "    \n",
    "    elif lambdas[j]<L:\n",
    "        lambdas[j]=L\n",
    "    \n",
    "    elif L<=lambdas[j]<=H:\n",
    "        lambdas[j]=lambdas[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate J Function\n",
    "Funtion to pick second Lagrange multiplier which results the max value of Error with the first Lagrange Multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_lambda(i):\n",
    "    elist=[]\n",
    "    for k in range(0,x.shape[0]):\n",
    "        e=E(k,b)\n",
    "        elist.append(abs(e-E(i,b)))\n",
    "    new_j=np.argmax(elist)\n",
    "    return new_j            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling Data\n",
    "Data is call for work. The Columns are selected here is according to the BREAST CANCER DATASET from WINCONSIN Hospital Easily find on Kaggle(www.kaggle.com).<br>\n",
    "Creating Dataset from original columns from the dataset so that you won't face any trouble regarding the dataset. I use Breast Cancer Dataset to train model and predict whether the person is having cancer or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./Dataset/Breast Cancer Dataset/Breast_Cancer_Data.csv\")\n",
    "\n",
    "# Taking Out Labels\n",
    "C=(data['diagnosis'])\n",
    "C.replace(to_replace=['B','M'],value=[1,-1],inplace=True)\n",
    "C=np.array(C).reshape(569,1)\n",
    "\n",
    "# Data Preprocessing removing Unnecessory columns\n",
    "data.drop([data.columns[0],data.columns[1],data.columns[32]],axis = 1, inplace = True)\n",
    "data=(data-np.mean(data,axis=0))/np.std(data,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_len=0.75*data.shape[0]\n",
    "train_data=data.iloc[-int(training_len):]\n",
    "test_data=data.iloc[:data.shape[0]-int(training_len)]\n",
    "x=np.array(train_data)\n",
    "\n",
    "C_train=C[:int(training_len)]\n",
    "C_test=C[int(training_len):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing parameters for Sequencial Minimal Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_passes=4\n",
    "passes=0\n",
    "tol=10**(-1)\n",
    "R=x.shape[0]\n",
    "\n",
    "lambdas=np.zeros((C_train.shape[0]))\n",
    "#lambdas[np.where(lambdas<0)[0]]=0\n",
    "lambdas_old=np.zeros((C_train.shape[0]))\n",
    "b=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Minimal Optimization (Refrenced from : CS229 Simplified SMO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "while passes < max_passes:\n",
    "    changed_alphas = 0\n",
    "    for i in range(0,x.shape[0]):\n",
    "        E1=E(i,b)\n",
    "        if (C_train[i]*E1 < -tol and lambdas[i] < R) or (C_train[i]*E1 > tol and lambdas[i] > 0):\n",
    "            j=second_lambda(i)\n",
    "            E2=E(j,b)\n",
    "            lambdas_old[i]=lambdas[i]\n",
    "            lambdas_old[j]=lambdas[j]\n",
    "            L,H=LnH(i,j,R)\n",
    "            if L == H:\n",
    "                continue\n",
    "            eta=compute_eta(i,j)\n",
    "            if eta >= 0:\n",
    "                continue\n",
    "            lambdas[j]=lambdas[j]+(C_train[j]*(int(E2-E1)))/eta\n",
    "            clip(H,L,j)\n",
    "            if (abs(lambdas[j] - lambdas_old[j]) < 10**(-5)):\n",
    "                continue\n",
    "            lambdas[i]=lambdas[i]-(C_train[i]*C_train[j]*(lambdas[j]-lambdas_old[j]))\n",
    "            b=compute_b(i,j,b,E1,E2,R)\n",
    "            changed_alphas = changed_alphas + 1\n",
    "    if changed_alphas == 0:\n",
    "        passes=passes + 1\n",
    "    else:\n",
    "        passes=0\n",
    "    print(passes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of support vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(lambdas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the parameters for Decision Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,t0=thetas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.12587412587412"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.array(test_data)\n",
    "predicted_labels=np.matmul(y,t)+t0\n",
    "predicted_labels[np.where(predicted_labels>0)[0]]=1\n",
    "predicted_labels[np.where(predicted_labels<=0)[0]]=-1\n",
    "o=np.count_nonzero(np.equal(C_test,predicted_labels))\n",
    "accuracy=(o/C_test.shape[0])*100\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.45070422535211"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_label=np.matmul(x,t)+t0\n",
    "training_label[np.where(training_label>0)[0]]=1\n",
    "training_label[np.where(training_label<0)[0]]=-1\n",
    "np.count_nonzero(np.equal(C_train,training_label))/C_train.shape[0]*100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
